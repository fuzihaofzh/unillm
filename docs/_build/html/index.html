<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Welcome to unillm’s documentation! &mdash; unillm  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js?v=b3ba4146"></script>
        <script src="_static/doctools.js?v=888ff710"></script>
        <script src="_static/sphinx_highlight.js?v=4825356b"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="unillm package" href="unillm.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="#" class="icon icon-home">
            unillm
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="unillm.html">unillm package</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="#">unillm</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="#" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Welcome to unillm’s documentation!</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="welcome-to-unillm-s-documentation">
<h1>Welcome to unillm’s documentation!<a class="headerlink" href="#welcome-to-unillm-s-documentation" title="Permalink to this heading"></a></h1>
<div class="toctree-wrapper compound">
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="unillm.html">unillm package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="unillm.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="unillm.html#module-unillm.unillm">unillm.unillm module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.ChatGPT"><code class="docutils literal notranslate"><span class="pre">ChatGPT</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.Claude"><code class="docutils literal notranslate"><span class="pre">Claude</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.Llama"><code class="docutils literal notranslate"><span class="pre">Llama</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.Mistral"><code class="docutils literal notranslate"><span class="pre">Mistral</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.MistralAI"><code class="docutils literal notranslate"><span class="pre">MistralAI</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.RAG"><code class="docutils literal notranslate"><span class="pre">RAG</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.UniLLM"><code class="docutils literal notranslate"><span class="pre">UniLLM</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.UniLLMBase"><code class="docutils literal notranslate"><span class="pre">UniLLMBase</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.cmd"><code class="docutils literal notranslate"><span class="pre">cmd()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.get_api_key"><code class="docutils literal notranslate"><span class="pre">get_api_key()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="unillm.html#unillm.unillm.run_cmd"><code class="docutils literal notranslate"><span class="pre">run_cmd()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="unillm.html#module-unillm.version">unillm.version module</a></li>
<li class="toctree-l2"><a class="reference internal" href="unillm.html#module-unillm">Module contents</a></li>
</ul>
</li>
</ul>
</div>
<section id="unillm-unified-large-language-model-interface">
<h2>UniLLM: Unified Large Language Model Interface<a class="headerlink" href="#unillm-unified-large-language-model-interface" title="Permalink to this heading"></a></h2>
<p>
<a href="https://opensource.org/licenses/MIT">
  <img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License">
</a>
<a href="https://pypi.org/project/unillm/">
  <img src="https://img.shields.io/pypi/v/unillm.svg" alt="PyPI">
</a>
<a href="https://github.com/fuzihaofzh/unillm">
  <img src="https://img.shields.io/github/stars/fuzihaofzh/unillm.svg?style=social&label=Star&maxAge=2592000" alt="GitHub stars">
</a>
</p>
<p>UniLLM is a versatile Python library and command-line tool designed to provide unified access to various large language models, including <a class="reference external" href="https://openai.com/chatgpt">ChatGPT</a>, <a class="reference external" href="https://llama.meta.com/">Llama</a>, <a class="reference external" href="https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2">Mistral (local)</a>, <a class="reference external" href="https://www.anthropic.com/">Claude</a>, <a class="reference external" href="https://mistral.ai/">MistralAI (API)</a>, and <a class="reference external" href="https://www.llamaindex.ai/">RAG (llamaindex)</a>. It is a wrapper that unifies the process of interacting with these models, whether you’re integrating them into your Python projects or using them directly via the command line.</p>
<section id="features">
<h3>Features<a class="headerlink" href="#features" title="Permalink to this heading"></a></h3>
<ul class="simple">
<li><p>Unified API for interacting with multiple language models.</p></li>
<li><p>Supports models like ChatGPT, LLaMA, Mistral, Claude, MistralAI, and RAG.</p></li>
<li><p>Easy-to-use command-line interface for quick interactions.</p></li>
<li><p>Extensible framework allowing the addition of more models in the future.</p></li>
</ul>
</section>
<section id="installation">
<h3>Installation<a class="headerlink" href="#installation" title="Permalink to this heading"></a></h3>
<p>To install UniLLM, you can use pip directly:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pip<span class="w"> </span>install<span class="w"> </span>unillm
</pre></div>
</div>
</section>
<section id="configuration">
<h3>Configuration<a class="headerlink" href="#configuration" title="Permalink to this heading"></a></h3>
<p>Before using UniLLM, you need to configure your API keys for the models you intend to use. Create a <code class="docutils literal notranslate"><span class="pre">.unillm.yaml</span></code> file in your home directory with the following structure:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">chatgpt</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">YOUR_CHATGPT_API_KEY</span>
<span class="nt">claude</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">YOUR_CLAUDE_API_KEY</span>
<span class="nt">mistralai</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">YOUR_MISTRALAI_API_KEY</span>
</pre></div>
</div>
<p>Replace <code class="docutils literal notranslate"><span class="pre">YOUR_MODEL_API_KEY</span></code> with the actual API keys for the models you plan to use.</p>
</section>
<section id="supported-models">
<h3>Supported Models<a class="headerlink" href="#supported-models" title="Permalink to this heading"></a></h3>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Model</p></th>
<th class="head text-center"><p>Support API</p></th>
<th class="head text-center"><p>Support Local</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>ChatGPT</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td><p>Llama</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>✅</p></td>
</tr>
<tr class="row-even"><td><p>Mistral</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
</tr>
<tr class="row-odd"><td><p>Claude</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td><p>RAG</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
</tr>
<tr class="row-odd"><td><p>Gemini</p></td>
<td class="text-center"><p>Soon</p></td>
<td class="text-center"><p></p></td>
</tr>
</tbody>
</table>
</section>
<section id="usage">
<h3>Usage<a class="headerlink" href="#usage" title="Permalink to this heading"></a></h3>
<section id="as-a-python-library">
<h4>As a Python Library<a class="headerlink" href="#as-a-python-library" title="Permalink to this heading"></a></h4>
<p>You can use UniLLM in your Python projects to interact with various language models seamlessly.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">unillm</span> <span class="kn">import</span> <span class="n">UniLLM</span>

<span class="c1"># Initialize the model (e.g., Llama with PEFT)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">UniLLM</span><span class="p">(</span><span class="s1">&#39;llama&#39;</span><span class="p">,</span> <span class="n">peft_path</span><span class="o">=</span><span class="s2">&quot;output/my_lora&quot;</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">1024</span><span class="p">)</span>

<span class="c1"># Generate a response</span>
<span class="n">response</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate_response</span><span class="p">(</span><span class="s2">&quot;Hello!&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="as-a-command-line-tool">
<h4>As a Command-Line Tool<a class="headerlink" href="#as-a-command-line-tool" title="Permalink to this heading"></a></h4>
<p>UniLLM also provides a command-line interface to interact with the supported language models.</p>
<p>To start the CLI, simply run:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>unillm
</pre></div>
</div>
<p>Follow the prompts to choose a model and enter your queries. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Please<span class="w"> </span>choose<span class="w"> </span>a<span class="w"> </span>model<span class="w"> </span>by<span class="w"> </span>number<span class="w"> </span><span class="o">(</span>default<span class="w"> </span>is<span class="w"> </span><span class="m">1</span><span class="o">)</span>:
<span class="m">1</span>:<span class="w"> </span>chatgpt
<span class="m">2</span>:<span class="w"> </span>llama
...

👨Please<span class="w"> </span>Ask<span class="w"> </span>a<span class="w"> </span>Question:<span class="w"> </span>How<span class="w"> </span>are<span class="w"> </span>you?
🤖<span class="w"> </span><span class="o">(</span>chatgpt<span class="o">)</span>:<span class="w"> </span>I<span class="s1">&#39;m just a virtual assistant, but I&#39;</span>m<span class="w"> </span>here<span class="w"> </span>to<span class="w"> </span><span class="nb">help</span><span class="w"> </span>you!
</pre></div>
</div>
<p>For using Llama with a PEFT model:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>unillm<span class="w"> </span>--model_type<span class="w"> </span>llama<span class="w"> </span>--peft_path<span class="w"> </span><span class="s2">&quot;output/my_lora&quot;</span><span class="w"> </span>--max_new_tokens<span class="w"> </span><span class="m">1024</span>
</pre></div>
</div>
<p>To exit, type <code class="docutils literal notranslate"><span class="pre">exit</span></code>.</p>
</section>
</section>
<section id="contributing">
<h3>Contributing<a class="headerlink" href="#contributing" title="Permalink to this heading"></a></h3>
<p>Contributions are welcome! If you have suggestions for improvements or new features, please feel free to fork the repository, create a feature branch, and submit a pull request.</p>
</section>
<section id="license">
<h3>License<a class="headerlink" href="#license" title="Permalink to this heading"></a></h3>
<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>
</section>
</section>
</section>
<section id="indices-and-tables">
<h1>Indices and tables<a class="headerlink" href="#indices-and-tables" title="Permalink to this heading"></a></h1>
<ul class="simple">
<li><p><a class="reference internal" href="genindex.html"><span class="std std-ref">Index</span></a></p></li>
<li><p><a class="reference internal" href="py-modindex.html"><span class="std std-ref">Module Index</span></a></p></li>
<li><p><a class="reference internal" href="search.html"><span class="std std-ref">Search Page</span></a></p></li>
</ul>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="unillm.html" class="btn btn-neutral float-right" title="unillm package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Zihao Fu.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>